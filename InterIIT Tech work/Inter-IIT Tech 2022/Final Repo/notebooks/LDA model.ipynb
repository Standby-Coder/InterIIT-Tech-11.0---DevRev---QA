{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: gensim in c:\\python311\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: click in c:\\python311\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python311\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\python311\\lib\\site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\python311\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\python311\\lib\\site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: Cython==0.29.32 in c:\\python311\\lib\\site-packages (from gensim) (0.29.32)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: pyfume in c:\\python311\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ckred\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: simpful in c:\\python311\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.9.0)\n",
      "Requirement already satisfied: fst-pso in c:\\python311\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\python311\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python311\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.25.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk gensim pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ckred\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ckred\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ckred\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "paragraph_data = pd.read_csv(\"train_input_paragraph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Theme</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer_possible</th>\n",
       "      <th>Answer_text</th>\n",
       "      <th>Answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>True</td>\n",
       "      <td>['2003']</td>\n",
       "      <td>[526]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What album made her a worldwide known artist?</td>\n",
       "      <td>True</td>\n",
       "      <td>['Dangerously in Love']</td>\n",
       "      <td>[505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Who managed the Destiny's Child group?</td>\n",
       "      <td>True</td>\n",
       "      <td>['Mathew Knowles']</td>\n",
       "      <td>[360]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyoncé rise to fame?</td>\n",
       "      <td>True</td>\n",
       "      <td>['late 1990s']</td>\n",
       "      <td>[276]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What role did Beyoncé have in Destiny's Child?</td>\n",
       "      <td>True</td>\n",
       "      <td>['lead singer']</td>\n",
       "      <td>[290]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Theme                                          Paragraph  \\\n",
       "0           2  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1           6  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2           7  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "3           8  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4           9  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                            Question  Answer_possible  \\\n",
       "0  When did Beyonce leave Destiny's Child and bec...             True   \n",
       "1      What album made her a worldwide known artist?             True   \n",
       "2             Who managed the Destiny's Child group?             True   \n",
       "3                     When did Beyoncé rise to fame?             True   \n",
       "4     What role did Beyoncé have in Destiny's Child?             True   \n",
       "\n",
       "               Answer_text Answer_start  \n",
       "0                 ['2003']        [526]  \n",
       "1  ['Dangerously in Love']        [505]  \n",
       "2       ['Mathew Knowles']        [360]  \n",
       "3           ['late 1990s']        [276]  \n",
       "4          ['lead singer']        [290]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Following the disbandment of Destiny's Child i...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A self-described \"modern-day feminist\", Beyonc...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Beyoncé Giselle Knowles was born in Houston, T...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Beyoncé attended St. Mary's Elementary School ...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          paragraph    theme\n",
       "0   1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  Beyoncé\n",
       "1   2  Following the disbandment of Destiny's Child i...  Beyoncé\n",
       "2   3  A self-described \"modern-day feminist\", Beyonc...  Beyoncé\n",
       "3   4  Beyoncé Giselle Knowles was born in Houston, T...  Beyoncé\n",
       "4   5  Beyoncé attended St. Mary's Elementary School ...  Beyoncé"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ckred\\AppData\\Local\\Temp\\ipykernel_13624\\1655334862.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  paragraph_data['paragraph'][idx] = paragraph_data['paragraph'][idx].lower()\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "docs = []\n",
    "\n",
    "for idx in range(len(paragraph_data)):\n",
    "    paragraph_data['paragraph'][idx] = paragraph_data['paragraph'][idx].lower()\n",
    "    docs.append(tokenizer.tokenize(paragraph_data['paragraph'][idx]))\n",
    "    \n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>following the disbandment of destiny's child i...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a self-described \"modern-day feminist\", beyonc...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>beyoncé giselle knowles was born in houston, t...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>beyoncé attended st. mary's elementary school ...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          paragraph    theme\n",
       "0   1  beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ b...  Beyoncé\n",
       "1   2  following the disbandment of destiny's child i...  Beyoncé\n",
       "2   3  a self-described \"modern-day feminist\", beyonc...  Beyoncé\n",
       "3   4  beyoncé giselle knowles was born in houston, t...  Beyoncé\n",
       "4   5  beyoncé attended st. mary's elementary school ...  Beyoncé"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_lemmatized = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases(docs_lemmatized, min_count=5)\n",
    "for idx in range(len(docs_lemmatized)):\n",
    "    for token in bigram[docs_lemmatized[idx]]:\n",
    "        if '_' in token:\n",
    "            docs_lemmatized[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(docs_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in docs_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What album made her a worldwide known artist?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Who managed the Destiny's Child group?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>When did Beyoncé rise to fame?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What role did Beyoncé have in Destiny's Child?</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question    theme\n",
       "0   1  When did Beyonce leave Destiny's Child and bec...  Beyoncé\n",
       "1   2      What album made her a worldwide known artist?  Beyoncé\n",
       "2   3             Who managed the Destiny's Child group?  Beyoncé\n",
       "3   4                     When did Beyoncé rise to fame?  Beyoncé\n",
       "4   5     What role did Beyoncé have in Destiny's Child?  Beyoncé"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_data = pd.read_csv(\"train_input_question.csv\")\n",
    "question_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ckred\\AppData\\Local\\Temp\\ipykernel_13624\\1948923624.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answer_data['answers'][i] = answer_data['answers'][i][2:-2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Dangerously in Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Mathew Knowles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>lead singer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id paragraph_id              answers\n",
       "0            1          [1]                 2003\n",
       "1            2          [1]  Dangerously in Love\n",
       "2            3          [1]       Mathew Knowles\n",
       "3            4          [1]           late 1990s\n",
       "4            5          [1]          lead singer"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_data = pd.read_csv(\"train_ground_truth.csv\")\n",
    "for i in range(len(answer_data)):\n",
    "    answer_data['answers'][i] = answer_data['answers'][i][2:-2]\n",
    "answer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "docs_qa = []\n",
    "\n",
    "for idx in range(len(paragraph_data)):\n",
    "    question = question_data['question'][idx].lower()\n",
    "    answer = answer_data['answers'][idx].lower()\n",
    "    question_tokens = [lemmatizer.lemmatize(token) for token in word_tokenize(question) if token not in stop_words]\n",
    "    answer_tokens = [lemmatizer.lemmatize(token) for token in word_tokenize(answer) if token not in stop_words]\n",
    "    docs_qa.append(question_tokens + answer_tokens)\n",
    "\n",
    "bigram_qa = Phrases(docs_qa, min_count=5)\n",
    "for idx in range(len(docs_qa)):\n",
    "    for token in bigram_qa[docs_qa[idx]]:\n",
    "        if '_' in token:\n",
    "            docs_qa[idx].append(token)\n",
    "\n",
    "dictionary_qa = corpora.Dictionary(docs_qa)\n",
    "\n",
    "corpus_qa = [dictionary_qa.doc2bow(text) for text in docs_qa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ldamodel_pre = LdaModel(corpus_qa, num_topics=10, id2word = dictionary_qa, passes=2000)\n",
    "ldamodel = LdaModel(corpus, num_topics=10, id2word = dictionary, passes=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.update(corpus_qa, chunksize=16, iterations=1, eval_every=10, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "target ttda dimensions do not match. Topics must be 16517 but was 70901 elements large",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m elda \u001b[39m=\u001b[39m EnsembleLda(corpus\u001b[39m=\u001b[39mcorpus_qa, id2word\u001b[39m=\u001b[39mdictionary_qa, num_topics\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, num_models\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39m# elda.add_model(ldamodel_pre)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# elda.recluster()\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m elda\u001b[39m.\u001b[39;49madd_model(LdaModel(corpus, num_topics\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, id2word \u001b[39m=\u001b[39;49m dictionary, passes\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m))\n\u001b[0;32m     23\u001b[0m elda\u001b[39m.\u001b[39mrecluster()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\gensim\\models\\ensemblelda.py:1008\u001b[0m, in \u001b[0;36mEnsembleLda.add_model\u001b[1;34m(self, target, num_new_models)\u001b[0m\n\u001b[0;32m   1005\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mensemble contains \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_models\u001b[39m}\u001b[39;00m\u001b[39m models and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mttda)\u001b[39m}\u001b[39;00m\u001b[39m topics now\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1007\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mttda\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m ttda\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m-> 1008\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1009\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget ttda dimensions do not match. Topics must be \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mttda\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m but was \u001b[39m\u001b[39m{\u001b[39;00mttda\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1010\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39melements large\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1011\u001b[0m     )\n\u001b[0;32m   1013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mttda \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mttda, ttda, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m   1015\u001b[0m \u001b[39m# tell recluster that the distance matrix needs to be regenerated\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: target ttda dimensions do not match. Topics must be 16517 but was 70901 elements large"
     ]
    }
   ],
   "source": [
    "from gensim.models.ensemblelda import EnsembleLda\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "common_dictionary = corpora.Dictionary(common_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "elda = EnsembleLda(corpus=corpus_qa, id2word=dictionary_qa, num_topics=10, num_models=4)\n",
    "\n",
    "# elda.add_model(ldamodel_pre)\n",
    "# elda.recluster()\n",
    "\n",
    "elda.add_model(LdaModel(corpus, num_topics=10, id2word = dictionary, passes=20))\n",
    "elda.recluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(question, ldamodel):\n",
    "    question_tokens = [lemmatizer.lemmatize(token) for token in word_tokenize(question.lower()) if token not in stop_words]\n",
    "    question_bow = dictionary.doc2bow(question_tokens)\n",
    "    topic_probs = ldamodel[question_bow]\n",
    "    return max(topic_probs, key=lambda x: x[1])[0]\n",
    "\n",
    "# Create a function to get the most likely answer for a question\n",
    "def get_answer(question, ldamodel):\n",
    "    question_topic = get_topic(question, ldamodel)\n",
    "    topic_answers = [text for text, topic in zip(docs_lemmatized, ldamodel[corpus]) if topic[0][0] == question_topic]\n",
    "    return max(topic_answers, key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ckred\\AppData\\Local\\Temp\\ipykernel_13624\\612108899.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  question_data['question'][i] = question_data['question'][i].lower()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(question_data)):\n\u001b[0;32m      2\u001b[0m     question_data[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m question_data[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m][i]\u001b[39m.\u001b[39mlower()\n\u001b[1;32m----> 3\u001b[0m     answer \u001b[39m=\u001b[39m get_answer(question_data[\u001b[39m'\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m'\u001b[39;49m][i], ldamodel)\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mQuestion: \u001b[39m\u001b[39m\"\u001b[39m, question_data[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m][i])\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAnswer: \u001b[39m\u001b[39m\"\u001b[39m, answer)\n",
      "Cell \u001b[1;32mIn[28], line 11\u001b[0m, in \u001b[0;36mget_answer\u001b[1;34m(question, ldamodel)\u001b[0m\n\u001b[0;32m      9\u001b[0m question_topic \u001b[39m=\u001b[39m get_topic(question, ldamodel)\n\u001b[0;32m     10\u001b[0m topic_answers \u001b[39m=\u001b[39m [text \u001b[39mfor\u001b[39;00m text, topic \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(docs_lemmatized, ldamodel[corpus]) \u001b[39mif\u001b[39;00m topic[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m question_topic]\n\u001b[1;32m---> 11\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39;49m(topic_answers, key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mlen\u001b[39;49m(x))\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "for i in range(len(question_data)):\n",
    "    question_data['question'][i] = question_data['question'][i].lower()\n",
    "    answer = get_answer(question_data['question'][i], ldamodel)\n",
    "    print(\"Question: \", question_data['question'][i])\n",
    "    print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
