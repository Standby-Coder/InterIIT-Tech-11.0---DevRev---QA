{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMcuac8ZKbj2",
        "outputId": "9d43f920-46b6-47d1-e39d-546d5c212a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 37.8 MB/s eta 0:00:00\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-22.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting farm-haystack[colab]\n",
            "  Downloading farm_haystack-1.12.2-py3-none-any.whl (598 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 598.7/598.7 kB 15.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (0.3.6)\n",
            "Collecting azure-ai-formrecognizer>=3.2.0b2\n",
            "  Downloading azure_ai_formrecognizer-3.2.0-py3-none-any.whl (228 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 228.4/228.4 kB 25.4 MB/s eta 0:00:00\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 981.5/981.5 kB 50.8 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.7.3)\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting elasticsearch<8,>=7.7\n",
            "  Downloading elasticsearch-7.17.8-py2.py3-none-any.whl (385 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 386.0/386.0 kB 36.7 MB/s eta 0:00:00\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 80.5 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting transformers[torch]==4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 85.5 MB/s eta 0:00:00\n",
            "Collecting sentence-transformers>=2.2.0\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 11.6 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (2.25.1)\n",
            "Collecting rapidfuzz<2.8.0,>=2.0.15\n",
            "  Downloading rapidfuzz-2.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 56.9 MB/s eta 0:00:00\n",
            "Collecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting posthog\n",
            "  Downloading posthog-2.2.0-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (4.3.3)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.7/16.7 MB 58.7 MB/s eta 0:00:00\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 5.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (4.64.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.3.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.10.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.0)\n",
            "Collecting quantulum3\n",
            "  Downloading quantulum3-0.8.1-py3-none-any.whl (10.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.7/10.7 MB 80.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (9.0.0)\n",
            "Collecting huggingface-hub>=0.5.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.3/190.3 kB 22.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.7)\n",
            "Collecting mmh3\n",
            "  Downloading mmh3-3.0.0-cp38-cp38-manylinux2010_x86_64.whl (50 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.0/50.0 kB 6.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pillow<=9.0.0 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.6/7.6 MB 94.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (2022.6.2)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (1.13.1+cu116)\n",
            "Collecting msrest>=0.6.21\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 11.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab]) (4.4.0)\n",
            "Collecting azure-core<2.0.0,>=1.23.0\n",
            "  Downloading azure_core-1.26.2-py3-none-any.whl (173 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 173.8/173.8 kB 21.0 MB/s eta 0:00:00\n",
            "Collecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from elasticsearch<8,>=7.7->farm-haystack[colab]) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from elasticsearch<8,>=7.7->farm-haystack[colab]) (2022.12.7)\n",
            "Collecting jarowinkler<2.0.0,>=1.2.0\n",
            "  Downloading jarowinkler-1.2.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.1/114.1 kB 15.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab]) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab]) (1.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab]) (0.14.1+cu116)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 44.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from langdetect->farm-haystack[colab]) (1.15.0)\n",
            "Collecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.5/147.5 kB 17.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (3.4.1)\n",
            "Collecting shap<1,>=0.40\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 575.9/575.9 kB 48.9 MB/s eta 0:00:00\n",
            "Collecting alembic<2\n",
            "  Downloading alembic-1.9.2-py3-none-any.whl (210 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.6/210.6 kB 25.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2.11.3)\n",
            "Requirement already satisfied: pytz<2023 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2022.7)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (0.4.3)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.0/184.0 kB 22.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (7.1.2)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 11.2 MB/s eta 0:00:00\n",
            "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (1.4.46)\n",
            "Collecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.3/82.3 kB 11.4 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (0.4)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (3.19.6)\n",
            "Requirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (9.0.0)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2.2.0)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (3.2.2)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->farm-haystack[colab]) (2.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (4.0.0)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff<2.0.0,>=1.10.0\n",
            "  Downloading backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from python-docx->farm-haystack[colab]) (4.9.2)\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.2/125.2 kB 15.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.8/dist-packages (from quantulum3->farm-haystack[colab]) (2.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tika->farm-haystack[colab]) (57.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.7/78.7 kB 11.6 MB/s eta 0:00:00\n",
            "Collecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab]) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab]) (0.8.10)\n",
            "Collecting urllib3<2,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.6/140.6 kB 16.6 MB/s eta 0:00:00\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.5.0-py3-none-any.whl (55 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.9/55.9 kB 7.6 MB/s eta 0:00:00\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 8.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (2.1.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->farm-haystack[colab]) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->farm-haystack[colab]) (1.0.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 8.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow->farm-haystack[colab]) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<4,>=2.11->mlflow->farm-haystack[colab]) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (3.0.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab]) (1.3.1)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 5.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow->farm-haystack[colab]) (0.56.4)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow->farm-haystack[colab]) (2.0.1)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap<1,>=0.40->mlflow->farm-haystack[colab]) (0.39.1)\n",
            "Building wheels for collected packages: sentence-transformers, langdetect, python-docx, seqeval, tika, databricks-cli, docopt\n",
            "  Building wheel for sentence-transformers (setup.py): started\n",
            "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=e3f9f6ca6b896de910a1f18ca7d578e3dbb9e8329ffaa433d982052dcfa5f08f\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/b4/1c/7509ecb4c391a7be4cdf2ff04df077a568cd52471007e436e6\n",
            "  Building wheel for langdetect (setup.py): started\n",
            "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=4560a5ee10e8c3de23f24c35108e8a702d71a6fb2ab5678bca663a7dbec0ca7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/af/97/539976921e53b1542a28f7160e511ac730b5d2cdcb41423ebb\n",
            "  Building wheel for python-docx (setup.py): started\n",
            "  Building wheel for python-docx (setup.py): finished with status 'done'\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184505 sha256=853c8c3d526800d11e69268912f800124435e33c7c87ccf5385175ad29b3b408\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/10/08/226d68e153dd4ec32713fbac0b1800b1311ff0adbc8eab3c06\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=220b149ab4aa0ec5c32a7d1bb66fd33d07e4c6210a18d27ea505ef5138b22b72\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/30/9b/6b670dac34775f2b7cc4e9b172202e81fbb4f9cdb103c1ca66\n",
            "  Building wheel for tika (setup.py): started\n",
            "  Building wheel for tika (setup.py): finished with status 'done'\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32642 sha256=ca0b787ad9ea08753791710a24ff12042ce92f933b10a9d38ed273873b457a88\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/24/b6/6d3480f25c91fcc9a55b4e76f180baf087ee2acd16e561a015\n",
            "  Building wheel for databricks-cli (setup.py): started\n",
            "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142894 sha256=872b73791fd207d5bb3086ed33281d10e5bac925f3f76a80cbc1c10bc82f045d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/0b/75/44edb38430dc44de74324d6e72d91d0d14d21df90349767335\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=e84c95441e0b79207b2b61ffa69eb3239b87ca0bb8ac581287d1fac89278e1e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cc/e3/f1e272f628fdb013d969acc99cfe2e031ea15b3efb74ffe842\n",
            "Successfully built sentence-transformers langdetect python-docx seqeval tika databricks-cli docopt\n",
            "Installing collected packages: tokenizers, sentencepiece, monotonic, mmh3, docopt, azure-common, websocket-client, urllib3, smmap, slicer, rank-bm25, querystring-parser, python-docx, pyjwt, num2words, Mako, langdetect, jarowinkler, isodate, importlib-metadata, gunicorn, backoff, requests, rapidfuzz, quantulum3, gitdb, elasticsearch, alembic, tika, shap, seqeval, posthog, huggingface-hub, gitpython, docker, databricks-cli, azure-core, transformers, msrest, mlflow, sentence-transformers, azure-ai-formrecognizer, farm-haystack\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.0.0\n",
            "    Uninstalling importlib-metadata-6.0.0:\n",
            "      Successfully uninstalled importlib-metadata-6.0.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.2 azure-ai-formrecognizer-3.2.0 azure-common-1.1.28 azure-core-1.26.2 backoff-1.11.1 databricks-cli-0.17.4 docker-6.0.1 docopt-0.6.2 elasticsearch-7.17.8 farm-haystack-1.12.2 gitdb-4.0.10 gitpython-3.1.30 gunicorn-20.1.0 huggingface-hub-0.12.0 importlib-metadata-5.2.0 isodate-0.6.1 jarowinkler-1.2.3 langdetect-1.0.9 mlflow-2.1.1 mmh3-3.0.0 monotonic-1.6 msrest-0.7.1 num2words-0.5.12 posthog-2.2.0 pyjwt-2.6.0 python-docx-0.8.11 quantulum3-0.8.1 querystring-parser-1.2.4 rank-bm25-0.2.2 rapidfuzz-2.7.0 requests-2.28.2 sentence-transformers-2.2.2 sentencepiece-0.1.97 seqeval-1.2.2 shap-0.41.0 slicer-0.0.7 smmap-5.0.0 tika-2.6.0 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.26.14 websocket-client-1.5.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tOzOIyvN2DB",
        "outputId": "4e911ad2-b8e7-447d-a0bc-1049cc8265ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehLW0Z9kKbj-"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqUTFl19KbkI"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "chown -R daemon:daemon elasticsearch-7.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IipueYvWKbkL"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIrfQEcbKbkP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5twiDDXuKbkR",
        "outputId": "ee929b1e-12f5-46f2-d80c-996c45e1be04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.telemetry:Haystack sends anonymous usage data to understand the actual usage and steer dev efforts towards features that are most meaningful to users. You can opt-out at anytime by calling disable_telemetry() or by manually setting the environment variable HAYSTACK_TELEMETRY_ENABLED as described for different operating systems on the documentation page. More information at https://docs.haystack.deepset.ai/docs/telemetry\n",
            "WARNING:haystack.utils.doc_store:Tried to start Elasticsearch through Docker but this failed. It is likely that there is already an existing Elasticsearch instance running. \n"
          ]
        }
      ],
      "source": [
        "from haystack.utils import launch_es\n",
        "launch_es()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hNjjylJKbkT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "\n",
        "# Get the host where Elasticsearch is running, default to localhost\n",
        "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
        "\n",
        "document_store = ElasticsearchDocumentStore(\n",
        "    host=host,\n",
        "    username=\"\",\n",
        "    password=\"\",\n",
        "    index=\"document\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vQ4DmrBMMCz",
        "outputId": "24e5bd1c-9d0d-4234-ee65-4100d07c3ebb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n"
          ]
        }
      ],
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore(use_bm25=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kwT0vCUKbkd",
        "outputId": "f0827263-d127-4b56-aca6-cfae15157731"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.nodes import TextConverter, PreProcessor\n",
        "\n",
        "indexing_pipeline = Pipeline()\n",
        "text_converter = TextConverter()\n",
        "preprocessor = PreProcessor(\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=True,\n",
        "    clean_empty_lines=True,\n",
        "    split_by=\"word\",\n",
        "    split_length=728,\n",
        "    split_overlap=20,\n",
        "    split_respect_sentence_boundary=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnJmJg6qKbkf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "indexing_pipeline.add_node(component=text_converter, name=\"TextConverter\", inputs=[\"File\"])\n",
        "indexing_pipeline.add_node(component=preprocessor, name=\"PreProcessor\", inputs=[\"TextConverter\"])\n",
        "indexing_pipeline.add_node(component=document_store, name=\"DocumentStore\", inputs=[\"PreProcessor\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "5gAo72K-QGkj",
        "outputId": "0cc04b6c-c2e7-4416-cc30-d9b6d3745f7d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e7b998e9-b4b7-4ecc-bbc0-daf7495b954a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Paragraph</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer_possible</th>\n",
              "      <th>Answer_text</th>\n",
              "      <th>Answer_start</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and become a solo singer?</td>\n",
              "      <td>True</td>\n",
              "      <td>['2003']</td>\n",
              "      <td>[526]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...</td>\n",
              "      <td>What album made her a worldwide known artist?</td>\n",
              "      <td>True</td>\n",
              "      <td>['Dangerously in Love']</td>\n",
              "      <td>[505]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...</td>\n",
              "      <td>Who managed the Destiny's Child group?</td>\n",
              "      <td>True</td>\n",
              "      <td>['Mathew Knowles']</td>\n",
              "      <td>[360]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...</td>\n",
              "      <td>When did Beyoncé rise to fame?</td>\n",
              "      <td>True</td>\n",
              "      <td>['late 1990s']</td>\n",
              "      <td>[276]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...</td>\n",
              "      <td>What role did Beyoncé have in Destiny's Child?</td>\n",
              "      <td>True</td>\n",
              "      <td>['lead singer']</td>\n",
              "      <td>[290]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7b998e9-b4b7-4ecc-bbc0-daf7495b954a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7b998e9-b4b7-4ecc-bbc0-daf7495b954a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7b998e9-b4b7-4ecc-bbc0-daf7495b954a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0    Theme  \\\n",
              "0           2  Beyoncé   \n",
              "1           6  Beyoncé   \n",
              "2           7  Beyoncé   \n",
              "3           8  Beyoncé   \n",
              "4           9  Beyoncé   \n",
              "\n",
              "                                                                         Paragraph  \\\n",
              "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...   \n",
              "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...   \n",
              "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...   \n",
              "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...   \n",
              "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4,...   \n",
              "\n",
              "                                                           Question  \\\n",
              "0  When did Beyonce leave Destiny's Child and become a solo singer?   \n",
              "1                     What album made her a worldwide known artist?   \n",
              "2                            Who managed the Destiny's Child group?   \n",
              "3                                    When did Beyoncé rise to fame?   \n",
              "4                    What role did Beyoncé have in Destiny's Child?   \n",
              "\n",
              "   Answer_possible              Answer_text Answer_start  Id  \n",
              "0             True                 ['2003']        [526]   0  \n",
              "1             True  ['Dangerously in Love']        [505]   1  \n",
              "2             True       ['Mathew Knowles']        [360]   2  \n",
              "3             True           ['late 1990s']        [276]   3  \n",
              "4             True          ['lead singer']        [290]   4  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/dev_rev_data/train_data.csv')\n",
        "df['Id']=[i for i in range(df.shape[0])]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vrn-FtjoK5a"
      },
      "outputs": [],
      "source": [
        "data_path='/content/data'\n",
        "try:\n",
        "  os.mkdir(data_path)\n",
        "except:\n",
        "  print(\"Here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRTxu4FYQRFZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def df_to_txt(df,path='/content/data',split_theme=False):\n",
        "  if split_theme==True:\n",
        "    for i in range(df.shape[0]):\n",
        "      if i %1000 == 0:\n",
        "        print(\"At i = \",i)\n",
        "      rw=df.iloc[i];\n",
        "      data_path=path+'/'+rw['Theme']\n",
        "      try:\n",
        "        os.mkdir(data_path)\n",
        "      except:\n",
        "        pass\n",
        "      file_path=data_path+'/'+str(rw['Id'])+'.txt'\n",
        "      file1 = open(file_path,\"w+\")\n",
        "      file1.write(rw['Paragraph'])\n",
        "      file1.close()\n",
        "  else:\n",
        "    for i in range(df.shape[0]):\n",
        "      if i %1000 == 0:\n",
        "        print(\"At i = \",i)\n",
        "      rw=df.iloc[i];\n",
        "      data_path=path+'/full'\n",
        "      try:\n",
        "        os.mkdir(data_path)\n",
        "      except:\n",
        "        pass\n",
        "      file_path=data_path+'/'+str(rw['Id'])+'.txt'\n",
        "      file1 = open(file_path,\"w+\")\n",
        "      file1.write(rw['Paragraph'])\n",
        "      file1.close()\n",
        "      \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk9v4S8OmJJW"
      },
      "outputs": [],
      "source": [
        "theme_list=df['Theme'].unique().tolist()\n",
        "len(theme_list)\n",
        "dict_doc_store={}\n",
        "index_pipeleine_store={}\n",
        "dict_retiever={}\n",
        "for theme in theme_list:\n",
        "  dict_doc_store[theme]=0\n",
        "  index_pipeleine_store[theme]=0\n",
        "  dict_retiever[theme]=0\n",
        "dict_id_to_context={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilt9hJEdkaFI"
      },
      "outputs": [],
      "source": [
        "def train_retriver(df,path='/content/data',by_theme=False):\n",
        "  df_to_txt(df,path,by_theme)\n",
        "  doc_dir='/content/data/'\n",
        "  if by_theme==True:\n",
        "    for theme in theme_list:\n",
        "      print(\"At theme = \",theme)\n",
        "      document_store_temp = ElasticsearchDocumentStore(\n",
        "        host=host,\n",
        "        username=\"\",\n",
        "        password=\"\",\n",
        "        index=\"document\"\n",
        "      )\n",
        "      doc_dir_tem=doc_dir+theme\n",
        "      indexing_pipeline_temp = Pipeline()\n",
        "      text_converter = TextConverter()\n",
        "      preprocessor = PreProcessor(\n",
        "          clean_whitespace=True,\n",
        "          clean_header_footer=True,\n",
        "          clean_empty_lines=True,\n",
        "          split_by=\"word\",\n",
        "          split_length=728,\n",
        "          split_overlap=20,\n",
        "          split_respect_sentence_boundary=True,\n",
        "      )\n",
        "      indexing_pipeline_temp.add_node(component=text_converter, name=\"TextConverter\", inputs=[\"File\"])\n",
        "      indexing_pipeline_temp.add_node(component=preprocessor, name=\"PreProcessor\", inputs=[\"TextConverter\"])\n",
        "      indexing_pipeline_temp.add_node(component=document_store_temp, name=\"DocumentStore\", inputs=[\"PreProcessor\"])\n",
        "      files_to_index = [doc_dir_tem + \"/\" + f for f in os.listdir(doc_dir_tem)]\n",
        "      resk=indexing_pipeline_temp.run_batch(file_paths=files_to_index)\n",
        "      for i in resk['documents']:\n",
        "        dict_id_to_context[i.id]=i.content\n",
        "      dict_doc_store[theme]=document_store_temp\n",
        "      index_pipeleine_store[theme]=indexing_pipeline_temp\n",
        "  else:\n",
        "    document_store_full = ElasticsearchDocumentStore(\n",
        "      host=host,\n",
        "      username=\"\",\n",
        "      password=\"\",\n",
        "      index=\"document\"\n",
        "    )\n",
        "    doc_dir+='full'\n",
        "    indexing_pipeline_full = Pipeline()\n",
        "    text_converter = TextConverter()\n",
        "    preprocessor = PreProcessor(\n",
        "        clean_whitespace=True,\n",
        "        clean_header_footer=True,\n",
        "        clean_empty_lines=True,\n",
        "        split_by=\"word\",\n",
        "        split_length=728,\n",
        "        split_overlap=20,\n",
        "        split_respect_sentence_boundary=True,\n",
        "    )\n",
        "    indexing_pipeline_full.add_node(component=text_converter, name=\"TextConverter\", inputs=[\"File\"])\n",
        "    indexing_pipeline_full.add_node(component=preprocessor, name=\"PreProcessor\", inputs=[\"TextConverter\"])\n",
        "    indexing_pipeline_full.add_node(component=document_store_full, name=\"DocumentStore\", inputs=[\"PreProcessor\"])\n",
        "    files_to_index = [doc_dir + \"/\" + f for f in os.listdir(doc_dir)]\n",
        "    resk=indexing_pipeline_full.run_batch(file_paths=files_to_index)\n",
        "    for i in resk['documents']:\n",
        "      dict_id_to_context[i.id]=i.content\n",
        "    dict_doc_store['full']=document_store_full\n",
        "    index_pipeleine_store['full']=indexing_pipeline_full\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBFiO3wHT75s"
      },
      "outputs": [],
      "source": [
        "train_retriver(df,by_theme=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaVy9lJXKbkg"
      },
      "outputs": [],
      "source": [
        "files_to_index = ['/content/data/full' + \"/\" + f for f in os.listdir('/content/data/full')]\n",
        "resk=indexing_pipeline.run_batch(file_paths=files_to_index[0:4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeJxRqxtO7Xo",
        "outputId": "65e588d6-602e-4193-ad71-bea0edbc9496"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-12695a23322b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'documents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'resk' is not defined"
          ]
        }
      ],
      "source": [
        "for i in resk['documents']:\n",
        "  print(i.id)\n",
        "  print(i.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi1H02S067-S",
        "outputId": "7571fc24-52da-4bf7-e86c-2ba016deafc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<haystack.document_stores.memory.InMemoryDocumentStore at 0x7f3f452fee50>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict_doc_store['full']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "d8dd71ca43bd499ea804e05e54f1d9ad",
            "d6140314c97344c18244cc54dd950df3",
            "440e98fd7e524471b221cd8468b2b85d",
            "c0a8b53664414c33ae4b6282768d61f1",
            "34d12ce539034315bb699cd18ea5cd29",
            "2cdc4822654944d697e934d943bc50c9",
            "6dc5a0c87a0a4a7bb82f3d658dccd39e"
          ]
        },
        "id": "PpZiOKA-pSSM",
        "outputId": "7cf673be-9582-4925-c040-4b33365edec1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8dd71ca43bd499ea804e05e54f1d9ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/835 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.model.language_model: * LOADING MODEL: 'deepset/tinyroberta-squad2' (Roberta)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6140314c97344c18244cc54dd950df3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/326M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
            "INFO:haystack.modeling.model.language_model:Loaded 'deepset/tinyroberta-squad2' (Roberta model) from model hub.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "440e98fd7e524471b221cd8468b2b85d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0a8b53664414c33ae4b6282768d61f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34d12ce539034315bb699cd18ea5cd29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cdc4822654944d697e934d943bc50c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dc5a0c87a0a4a7bb82f3d658dccd39e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n"
          ]
        }
      ],
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "from haystack.nodes import FARMReader\n",
        "reader = FARMReader(model_name_or_path=\"deepset/tinyroberta-squad2\", use_gpu=True)\n",
        "from haystack import Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9RP8Kwx8Q6m"
      },
      "outputs": [],
      "source": [
        "if 'full' in theme_list:\n",
        "  print('present')\n",
        "else :\n",
        "  theme_list.append('full')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q_fs7p2pSYE"
      },
      "outputs": [],
      "source": [
        "dict_query_pipeline={}\n",
        "for theme in theme_list:\n",
        "  dict_retiever[theme]=BM25Retriever(document_store=dict_doc_store[theme])\n",
        "  querying_pipeline = Pipeline()\n",
        "  querying_pipeline.add_node(component=dict_retiever[theme], name=\"Retriever\", inputs=[\"Query\"])\n",
        "  querying_pipeline.add_node(component=reader, name=\"Reader\", inputs=[\"Retriever\"])\n",
        "  dict_query_pipeline[theme]=querying_pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWNWc8NMpIr7"
      },
      "outputs": [],
      "source": [
        "def predict(theme,question,top_k_reader=1,top_k_retriever=2):\n",
        "  start=time.time()\n",
        "  querying_pipeline=dict_query_pipeline[theme]\n",
        "  # querying_pipeline = Pipeline()\n",
        "  # querying_pipeline.add_node(component=retiever, name=\"Retriever\", inputs=[\"Query\"])\n",
        "  # querying_pipeline.add_node(component=reader, name=\"Reader\", inputs=[\"Retriever\"])\n",
        "  prediction = querying_pipeline.run(\n",
        "      query=question,\n",
        "      params={\n",
        "          \"Retriever\": {\"top_k\": top_k_retriever},\n",
        "          \"Reader\": {\"top_k\": top_k_reader}\n",
        "      }\n",
        "  )\n",
        "  best_pred=[0,\"none\",\"doc\",\"id\"]\n",
        "  for ans in prediction['answers']:\n",
        "    if best_pred[0]<=ans.score:\n",
        "      best_pred=[ans.score,ans.answer,dict_id_to_context[ans.document_id],ans.document_id]\n",
        "\n",
        "  print(\"Els time = \",time.time()-start)\n",
        "\n",
        "  return [best_pred,time.time()-start]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXwLB6WzKbko"
      },
      "outputs": [],
      "source": [
        "retirever=dict_retiever['full']\n",
        "ls=[reader,retirever]\n",
        "preds=predict('full',\"How long have international oil companies been in Nigeria?\",2,2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1nk-G_a-hgg",
        "outputId": "46cb678a-a52f-4add-8857-f1cc2be2d778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.9121561050415039,\n",
              "  'decades',\n",
              "  'The Niger Delta Nembe Creek Oil field was discovered in 1973 and produces from middle Miocene deltaic sandstone-shale in an anticline structural trap at a depth of 2–4 km. In June 2013, the company announced a strategic review of its operations in Nigeria, hinting that assets could be divested. While many international oil companies have operated there for decades, by 2014 most were making moves to divest their interests, citing a range of issues including oil theft. In August 2014, Shell Oil Company said it was finalising its interests in four Nigerian oil fields.',\n",
              "  'f72829c4f17176a9abac4de8abac8279'],\n",
              " 2.0400357246398926]"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNnyR157PDk8"
      },
      "source": [
        "Dont Use Code after This cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6A8ig4W_iUo"
      },
      "outputs": [],
      "source": [
        "%pip install -U gensim\n",
        "%pip install ray\n",
        "%pip install torch\n",
        "%pip install transformers\n",
        "%pip install scikit-learn\n",
        "%pip install psutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8AZALgz_nqu"
      },
      "outputs": [],
      "source": [
        "theme='Nigeria'\n",
        "df_new=df[df[\"Theme\"]==theme]\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMF_eHp5_59T",
        "outputId": "d028fffb-331e-435d-dfa5-919ba9dfd4a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions=df_new['Question'].tolist()\n",
        "for i in range(len(questions)):\n",
        "  questions[i]=[theme,questions[i]]\n",
        "len(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qcKsK5oAaKq",
        "outputId": "45148253-14d2-4873-d26d-a07376505f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of available CPUs: 2\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from transformers import pipeline\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import psutil\n",
        "import ray\n",
        "num_cpus = psutil.cpu_count(logical=True)\n",
        "print('Number of available CPUs:', num_cpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLRRZMz9GXNp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "gKV3HqvRAEoG",
        "outputId": "6916bfc2-f560-4b69-8258-8876c18bdba9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-26 17:27:50,699\tINFO worker.py:1370 -- Calling ray.init() again after it has already been called.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of available CPUs: 2\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-b5871b2e69f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Start Ray cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_reinit_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipe_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_doc_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# @ray.remote decorator enables to use this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(value, _owner)\u001b[0m\n\u001b[1;32m   2373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mprofiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ray.put\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m             \u001b[0mobject_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserialize_owner_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mObjectStoreFullError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m             logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mput_object\u001b[0;34m(self, value, object_ref, owner_address)\u001b[0m\n\u001b[1;32m    609\u001b[0m             ), \"Local Mode does not support inserting with an ObjectRef\"\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mserialized_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_serialization_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;31m# This *must* be the first place that we construct this python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;31m# ObjectRef because an entry with 0 local references is created when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/serialization.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mRawSerializedObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize_to_msgpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/serialization.py\u001b[0m in \u001b[0;36m_serialize_to_msgpack\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpython_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_METADATA_TYPE_PYTHON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             pickle5_serialized_object = self._serialize_to_pickle5(\n\u001b[0m\u001b[1;32m    429\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpython_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/serialization.py\u001b[0m in \u001b[0;36m_serialize_to_pickle5\u001b[0;34m(self, metadata, value)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_and_clear_contained_object_refs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_out_of_band_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/serialization.py\u001b[0m in \u001b[0;36m_serialize_to_pickle5\u001b[0;34m(self, metadata, value)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_in_band_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             inband = pickle.dumps(\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"recursion\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36m__getstate__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot pickle {self.__class__.__name__!r} object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'socket' object"
          ]
        }
      ],
      "source": [
        "num_cpus = psutil.cpu_count(logical=True)\n",
        "print('Number of available CPUs:', num_cpus)\n",
        "st=time.time()\n",
        "# Start Ray cluster\n",
        "ray.init(num_cpus=num_cpus, ignore_reinit_error=True)\n",
        "pipe_id = ray.put(reader)\n",
        "\n",
        "# @ray.remote decorator enables to use this \n",
        "# function in distributed setting\n",
        "@ray.remote\n",
        "def predict_pipe(full_pipeline,question,pipeline):\n",
        "    return predict(full_pipeline,theme,question,2,2)\n",
        "\n",
        "en = time.time()\n",
        "print('Loading Time :', str(timedelta(seconds=en-st)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1lRj4AAAW-m"
      },
      "outputs": [],
      "source": [
        "def multi_process_predict(inputs):\n",
        "    start = time.time()\n",
        "    # Run the function using multiple cores and gather the results\n",
        "    predictions = ray.get([predict_pipe.remote(pipeline,theme,question) for theme,question,pipeline in inputs])\n",
        "    end = time.time()\n",
        "    print('Prediction time:', str(timedelta(seconds=end-start)))\n",
        "    \n",
        "    return predictions,end-start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDQr3ng_DECj"
      },
      "outputs": [],
      "source": [
        "final_pred=multi_process_predict(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXFFPOkmE53a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "c8afb3981a61b3e570e10e23d3dc40ff584d336f78ce7476460a01ea41ad0ace"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
