{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-21T08:37:07.209352Z","iopub.execute_input":"2023-01-21T08:37:07.210389Z","iopub.status.idle":"2023-01-21T08:37:07.232522Z","shell.execute_reply.started":"2023-01-21T08:37:07.210281Z","shell.execute_reply":"2023-01-21T08:37:07.231678Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%pip install -U gensim","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:37:15.336784Z","iopub.execute_input":"2023-01-21T08:37:15.337144Z","iopub.status.idle":"2023-01-21T08:37:29.364532Z","shell.execute_reply.started":"2023-01-21T08:37:15.337114Z","shell.execute_reply":"2023-01-21T08:37:29.363216Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (4.0.1)\nCollecting gensim\n  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.21.6)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.7.3)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (6.3.0)\nInstalling collected packages: gensim\n  Attempting uninstall: gensim\n    Found existing installation: gensim 4.0.1\n    Uninstalling gensim-4.0.1:\n      Successfully uninstalled gensim-4.0.1\nSuccessfully installed gensim-4.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom nltk.tokenize import word_tokenize\nimport os\nimport gensim","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:37:29.367883Z","iopub.execute_input":"2023-01-21T08:37:29.368209Z","iopub.status.idle":"2023-01-21T08:37:30.426683Z","shell.execute_reply.started":"2023-01-21T08:37:29.368171Z","shell.execute_reply":"2023-01-21T08:37:30.425714Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = []\n\ndf=pd.read_csv('/kaggle/input/devrev/train_data.csv')\nfor i in range(df.shape[0]):\n    rw=df.iloc[i]\n    data.append('Paragraph')\n\ntagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:37:32.079993Z","iopub.execute_input":"2023-01-21T08:37:32.080915Z","iopub.status.idle":"2023-01-21T08:37:46.110320Z","shell.execute_reply.started":"2023-01-21T08:37:32.080880Z","shell.execute_reply":"2023-01-21T08:37:46.109145Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df['id']=list(i for i in range(df.shape[0]))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:37:46.115200Z","iopub.execute_input":"2023-01-21T08:37:46.117482Z","iopub.status.idle":"2023-01-21T08:37:46.184341Z","shell.execute_reply.started":"2023-01-21T08:37:46.117445Z","shell.execute_reply":"2023-01-21T08:37:46.183529Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0    Theme                                          Paragraph  \\\n0           2  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n1           6  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n2           7  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n3           8  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n4           9  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n\n                                            Question  Answer_possible  \\\n0  When did Beyonce leave Destiny's Child and bec...             True   \n1      What album made her a worldwide known artist?             True   \n2             Who managed the Destiny's Child group?             True   \n3                     When did Beyoncé rise to fame?             True   \n4     What role did Beyoncé have in Destiny's Child?             True   \n\n               Answer_text Answer_start  id  \n0                 ['2003']        [526]   0  \n1  ['Dangerously in Love']        [505]   1  \n2       ['Mathew Knowles']        [360]   2  \n3           ['late 1990s']        [276]   3  \n4          ['lead singer']        [290]   4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Theme</th>\n      <th>Paragraph</th>\n      <th>Question</th>\n      <th>Answer_possible</th>\n      <th>Answer_text</th>\n      <th>Answer_start</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>When did Beyonce leave Destiny's Child and bec...</td>\n      <td>True</td>\n      <td>['2003']</td>\n      <td>[526]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>What album made her a worldwide known artist?</td>\n      <td>True</td>\n      <td>['Dangerously in Love']</td>\n      <td>[505]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>Who managed the Destiny's Child group?</td>\n      <td>True</td>\n      <td>['Mathew Knowles']</td>\n      <td>[360]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>When did Beyoncé rise to fame?</td>\n      <td>True</td>\n      <td>['late 1990s']</td>\n      <td>[276]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>Beyoncé</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>What role did Beyoncé have in Destiny's Child?</td>\n      <td>True</td>\n      <td>['lead singer']</td>\n      <td>[290]</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#FULL\nmax_epochs = 1\nvec_size = 728\nalpha = 0.025\n\nmodel_full = gensim.models.doc2vec.Doc2Vec(vector_size=vec_size, min_count=2, epochs=70,dm=1,alpha = 0.025)\n  \nmodel_full.build_vocab(tagged_data)\n\nfor epoch in range(max_epochs):\n    print('iteration {0}'.format(epoch))\n    model_full.train(tagged_data,\n                total_examples=model_full.corpus_count,\n                epochs=model_full.epochs)\n    # decrease the learning rate\n    model_full.alpha -= 0.0002\n    # fix the learning rate, no decay\n    model_full.min_alpha = model_full.alpha\n\nmodel_full.save(\"d2v.model\")\nprint(\"Model Saved\")","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:37:52.950366Z","iopub.execute_input":"2023-01-21T08:37:52.951043Z","iopub.status.idle":"2023-01-21T08:42:03.655450Z","shell.execute_reply.started":"2023-01-21T08:37:52.951007Z","shell.execute_reply":"2023-01-21T08:42:03.653543Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"iteration 0\nModel Saved\n","output_type":"stream"}]},{"cell_type":"code","source":"from gensim.models.doc2vec import Doc2Vec\n\nmodel_full= Doc2Vec.load(\"d2v.model\")\n#to find the vector of a document which is not in training data\ntest_data = word_tokenize(\"I love chatbots\".lower())\nv1 = model_full.infer_vector(test_data)\nprint(\"V1_infer\", v1)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:42:03.657417Z","iopub.execute_input":"2023-01-21T08:42:03.657757Z","iopub.status.idle":"2023-01-21T08:42:03.764199Z","shell.execute_reply.started":"2023-01-21T08:42:03.657721Z","shell.execute_reply":"2023-01-21T08:42:03.763091Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"V1_infer [-6.59395242e-04 -3.20572086e-04  4.08350694e-04 -2.78144667e-04\n -2.86153168e-04 -5.18208602e-04 -2.91162374e-04 -2.38278939e-04\n  2.45034862e-05 -4.52721433e-05  3.77281831e-04  5.01612385e-06\n -5.32023958e-04  2.41687580e-04 -6.12406759e-04  5.17938985e-04\n -5.86889917e-04 -1.55910806e-04  6.48144283e-04 -1.31023990e-04\n -3.23347012e-05 -6.59853918e-04 -6.17475307e-04  6.75780408e-04\n  6.69586356e-04  1.22422367e-04  2.90750468e-04  3.62527004e-04\n  3.44352971e-04  5.62615227e-04  2.73574347e-04 -2.34684412e-04\n  3.61755170e-04 -6.45121618e-05  2.36444510e-04 -3.71791757e-05\n -5.64177608e-05  5.92060154e-04 -5.65314840e-05  3.59754398e-04\n -5.21973125e-04 -2.57646549e-04  3.25425877e-04  1.83583950e-04\n  4.30588203e-04 -5.38295950e-04 -2.59253593e-05 -1.39121621e-04\n -5.82587090e-04  3.44180560e-04  2.63175461e-04  6.53081806e-04\n  4.24122758e-04  3.48552654e-04 -6.82640064e-04 -7.26741928e-05\n  6.24094857e-04  2.67156138e-04  2.72353995e-04 -2.33694707e-04\n  1.48324354e-04  5.59921027e-04 -3.10331088e-04 -5.44158218e-04\n -5.42881666e-04  5.97505597e-04  1.76701576e-06 -6.47003821e-04\n  1.14781513e-04 -3.68437351e-04  5.61230525e-04  2.89293937e-04\n -8.84613144e-07 -6.82351165e-05 -5.82541805e-04 -2.84444104e-04\n -5.46796771e-04 -3.41677049e-04 -4.02016536e-04 -8.72186647e-05\n -2.44167488e-04  6.28010661e-04 -4.40501870e-04  5.93010860e-04\n -3.64753156e-04 -5.65964961e-04 -5.23272669e-04  5.84617839e-04\n -4.49061481e-04 -2.70182005e-04 -6.86679559e-04 -2.53396702e-05\n  1.12545116e-04 -5.30661026e-04  1.53081346e-04 -1.94882057e-04\n -3.47161636e-04 -4.36656410e-04 -4.64499899e-04  5.60575689e-04\n -5.00586582e-04  2.07995559e-04  6.78897894e-04 -2.72095698e-04\n  1.24981525e-04 -4.50515334e-04  3.99112876e-04  2.59974913e-04\n  9.63635175e-05 -5.76184306e-04  1.25153209e-04  4.63527977e-04\n  4.93694155e-04 -2.67759984e-04  5.71881130e-04 -1.60911339e-04\n -4.27047227e-04  1.92691179e-04 -2.41412316e-04  2.94696336e-04\n  2.05167453e-04  6.14961027e-04 -4.84310207e-04 -1.19928145e-05\n -3.59954756e-05 -2.55157589e-04 -5.92086348e-04  1.74454777e-04\n -6.82220911e-04  1.55196412e-05  1.93134285e-04  4.28231957e-04\n  5.72840916e-04  6.84072031e-04  4.15039016e-04  8.95652338e-05\n -5.47555392e-04 -2.15976892e-04  1.70832311e-04 -5.93428733e-04\n -6.29051472e-04  4.27829276e-04 -2.59704015e-04  5.24317496e-04\n  3.26818903e-04  5.76069462e-04 -3.05612921e-04 -1.16901901e-04\n  6.48878282e-04 -6.84052648e-04 -6.23852771e-04  6.65203319e-04\n -4.76273854e-04 -6.57440687e-04  2.28724719e-04  4.79841867e-04\n -3.31847987e-04 -5.81346510e-04  4.63204575e-04  4.94528445e-04\n  1.96059154e-05 -1.24523154e-04 -2.03376294e-06  6.15652301e-04\n -5.75238664e-04  5.78622748e-05  5.23242750e-04 -8.80399093e-05\n -2.09165722e-04  7.52530759e-05  4.39622410e-04  6.01712498e-04\n  4.83789219e-04  3.94109607e-04  1.33756432e-04 -3.96336080e-04\n -3.50189890e-04 -5.63421054e-04  4.02435893e-04 -4.05508072e-05\n -5.09554811e-04  4.47986473e-04  2.32820166e-04 -2.03935895e-04\n  4.75193287e-04 -5.71617682e-04 -5.59345295e-04 -5.06716082e-04\n  2.72331003e-04 -3.18750303e-04 -3.92214686e-04 -1.21681653e-04\n -5.39488799e-04 -5.81838831e-04  6.14182907e-04 -5.32151025e-04\n -4.54776491e-05  4.44007921e-04  6.20082021e-04 -2.59214663e-04\n -3.22722073e-04 -2.74086022e-04 -1.72109154e-04  3.01851018e-04\n  8.72166638e-05  6.60669291e-04  2.33536892e-04 -3.21872038e-04\n  2.16650606e-05 -3.27354355e-05  1.17280244e-04  3.45788081e-04\n -1.33519119e-04  2.52311875e-04  5.01228387e-05  5.04178519e-04\n -1.20086537e-04 -6.62128325e-04 -4.29088366e-04  3.16234247e-04\n  1.42387711e-04 -6.54745556e-04  5.86497830e-04  2.70023855e-04\n  2.55800114e-04 -5.83284243e-04 -1.10659539e-05  6.16948993e-04\n -2.73224578e-04  4.10926295e-04 -5.81820903e-04 -5.45645948e-04\n  1.59740448e-05  8.50983197e-05 -5.06432087e-04  6.82161422e-04\n -5.38287160e-04 -1.03813931e-04 -5.89961128e-04  5.85058180e-04\n -1.40577191e-04  5.58612577e-04 -6.16082631e-04 -9.49191672e-05\n  4.13181435e-04  6.14972378e-04  9.52256232e-05 -4.50318941e-04\n  3.56483011e-04 -5.99733903e-04 -5.93797420e-04 -4.91661020e-04\n -5.75175509e-04 -4.09026310e-04 -1.13999857e-04 -1.55272312e-04\n  5.93804813e-04 -6.05921727e-04 -4.94716514e-05  4.40928794e-04\n -5.61417313e-04 -4.86531848e-04 -3.27075453e-04 -3.23472777e-04\n -4.47213533e-04 -4.54477238e-04  2.78909050e-04 -2.95267586e-04\n  3.57918529e-04  8.30675854e-05  8.97904683e-05 -2.71537516e-04\n -2.91947392e-04 -2.46489886e-04  2.68656382e-04 -6.61957543e-04\n -3.31289280e-04  5.28376317e-04 -2.08830970e-04  1.00041158e-04\n -4.70055238e-04 -1.76697024e-04 -2.01646078e-04 -1.04400075e-04\n -1.73404405e-04 -5.30226622e-04  4.38710413e-04 -4.04509046e-04\n -2.89109099e-04 -6.35677134e-04 -6.69895264e-04 -2.19680005e-04\n  5.84392576e-04 -5.94416342e-04  6.51182083e-04  4.44951613e-04\n -2.75823695e-04 -3.89489986e-04  2.85806251e-04  9.05695856e-07\n -3.25661735e-04  2.15167689e-04  4.66307596e-04 -1.50080486e-05\n  5.11905877e-04  1.88753751e-04  3.70181369e-04 -1.91826126e-04\n -4.89200524e-04  6.56929740e-04 -7.10129170e-05 -4.48935134e-05\n  2.35847067e-04 -1.51031621e-04  2.34928841e-04 -9.54423085e-05\n -5.46771160e-04  2.09484951e-05 -3.06235277e-04  1.78087212e-04\n -5.30303107e-04  4.09661909e-04  6.77160861e-04 -4.44394391e-06\n  1.16247400e-04 -3.09378724e-04  4.55029076e-05 -1.97676345e-04\n -6.08624425e-04  6.47104243e-05  4.48589301e-04 -2.87838029e-05\n -4.39544703e-04  5.80403503e-05  3.89937282e-04 -5.13278297e-04\n -6.08857314e-04  3.42513435e-04 -3.88156186e-04 -1.35914146e-04\n -3.48632631e-04  6.82222715e-04  4.00358171e-04  4.61925112e-04\n -2.11555176e-04 -1.21882127e-04 -2.25369135e-04  6.02038112e-04\n  5.02432056e-04  6.59335114e-04  1.36296832e-04 -4.11796296e-04\n  3.10577132e-04 -2.01749193e-04  5.43958682e-04  3.73600196e-04\n  6.81582605e-04 -4.35988244e-04  5.02175593e-04 -6.44138549e-04\n  2.77546002e-04  2.51974387e-04  5.26320888e-04  8.31910529e-06\n  1.64319688e-04  7.99791178e-06 -2.44518713e-04 -3.86084663e-04\n -3.71124101e-04  1.18914788e-04  5.01237169e-04 -4.29578708e-04\n -6.56626304e-04  5.94562967e-04 -3.26858979e-04  6.38242869e-04\n -3.07190552e-04  1.18956792e-04  1.84013697e-04  5.24812436e-04\n  4.45004989e-04 -7.47735321e-05 -3.07660142e-04 -5.47879492e-04\n -1.87570171e-04  5.93982288e-04  3.11013602e-04  5.67339303e-04\n  4.00625169e-04 -4.34568123e-04 -6.48990797e-04  6.80048368e-04\n  2.12742656e-04 -6.22198335e-04 -5.72042132e-04  5.78472682e-04\n -3.59322497e-04  5.46397408e-04 -1.12643611e-04 -5.65759896e-04\n  6.08801376e-04 -2.50750309e-04  2.91810837e-04  2.07275560e-04\n  6.84096245e-04 -3.59053549e-04 -1.48751657e-04 -4.27108287e-04\n -1.91609157e-04 -6.55545620e-04 -8.90124138e-05  4.09646746e-04\n  1.08218046e-04 -2.18654077e-05 -3.47508758e-04  1.64327546e-04\n -5.03269199e-04 -1.97212648e-04  4.15361836e-04  1.67352235e-04\n -3.46999237e-04  3.52569419e-04  2.08428115e-04  1.11217843e-04\n -3.07204376e-04  6.41285500e-04  2.57347652e-04  4.83066920e-04\n  3.63030209e-04 -3.72585026e-04 -1.89708328e-04 -1.14183342e-04\n  5.12578234e-04  5.48800046e-04 -9.31244813e-06  1.83477590e-04\n -1.53688277e-04  2.62929352e-05  2.54833838e-04 -5.24183735e-04\n -4.87919373e-04  5.69491276e-05 -2.94812548e-04 -8.46087496e-05\n  1.45021375e-04  2.64312053e-04  1.23001300e-04 -3.96243093e-04\n -4.31452463e-05  1.73727076e-05 -6.39214704e-04 -1.36267554e-04\n  6.74800831e-04 -8.51757359e-05 -2.83589034e-04 -1.27442792e-04\n  1.05751824e-04 -1.19934244e-04 -3.68280860e-04  3.09756084e-04\n  5.35915198e-04 -2.29093275e-04  2.42383932e-04 -4.52144799e-04\n -1.37156880e-04 -3.57691810e-04  3.19343264e-04 -2.59822176e-04\n -6.96536736e-05  6.21253916e-04  6.65196625e-04 -5.16232220e-04\n -1.10829758e-04 -6.73607050e-04  6.24994107e-04  4.14964743e-04\n  3.19000283e-05  4.93826286e-04 -5.35976433e-04 -6.54570875e-04\n  6.76990312e-04 -6.32267445e-04  3.50466958e-04 -5.73038065e-04\n  6.35184173e-04  2.52146478e-04  1.38750283e-05  4.94573731e-04\n -1.38411400e-04 -4.46571677e-04  4.53168068e-05 -4.48722509e-04\n  6.27956702e-04 -1.03413484e-04 -1.49787287e-04  3.38873360e-04\n -2.39724686e-04  2.34601262e-04 -6.59720157e-04 -4.39432100e-04\n -4.13389644e-04 -2.30170292e-04  2.34032312e-04  5.73580561e-04\n -4.09089349e-04 -1.13564696e-04 -6.84455095e-04 -6.52738439e-04\n  1.48751409e-04 -2.11931881e-04 -1.84769815e-04  2.46620039e-04\n  3.57001700e-04  6.72335795e-04 -3.63022176e-04  3.66751716e-04\n  3.06674337e-04  5.49702963e-04 -3.20275867e-04  5.67140814e-04\n -3.10077652e-04 -1.19490935e-04 -6.18004822e-04 -5.64958667e-04\n  3.95283831e-04  3.46936955e-04 -5.51880163e-04  6.93265029e-05\n  6.54636242e-04  3.00025888e-04 -2.98461120e-04 -1.88116101e-05\n -9.28784448e-06 -2.27215030e-04 -2.22043804e-04  3.38265701e-04\n -6.07367081e-04 -1.27565232e-04 -1.70790066e-04 -5.49520249e-04\n  2.02502764e-04 -4.13607522e-05 -2.34732550e-04  2.65110983e-04\n  3.99115306e-05  4.74782428e-04 -2.98586110e-05  6.08186936e-04\n  6.03750988e-04 -4.11966670e-04 -3.66133390e-05  1.51780274e-04\n -1.09127344e-04 -2.75332597e-04 -2.24200950e-04  2.32040635e-04\n  2.53857579e-04 -1.96916721e-04  4.08302119e-04  3.21251282e-04\n  4.12684720e-04 -2.52986763e-04 -5.36600477e-04 -2.40022709e-04\n -2.20957940e-04  5.96834907e-05  2.29544530e-04 -3.58155376e-04\n  5.21343667e-04  1.76142203e-04 -4.43687488e-04  3.18050297e-04\n -1.75574445e-04  6.61039317e-04  8.32676888e-05  6.39423088e-04\n -4.08832100e-04 -4.09673201e-04 -6.27858739e-04 -4.60384530e-04\n -1.52135777e-04  9.08771908e-05  3.06794100e-04  5.69873315e-04\n -3.76687123e-04 -3.92316470e-05  3.82867584e-04  5.34669030e-04\n  3.00838554e-04 -3.28660302e-04  1.57492996e-05 -2.64021772e-04\n -6.61091413e-04 -2.85177230e-04  2.73406506e-04 -5.34786086e-04\n  6.38546189e-04 -5.18404297e-04  3.09847965e-04 -5.39490662e-04\n  1.43403213e-06 -3.56536475e-05 -5.20087138e-04 -7.89486876e-05\n -4.66614292e-05 -6.41717168e-04 -2.87605100e-04  2.46792697e-05\n  5.48369135e-04 -2.74232996e-04 -4.95529443e-04 -2.86617607e-04\n  3.70872789e-04 -5.92965866e-04 -5.68658870e-04 -1.98692695e-04\n  4.69696301e-04 -4.55059198e-04 -1.48225459e-04 -1.92849766e-04\n -5.49356046e-04  6.73447357e-05 -5.52274229e-04 -2.14607338e-04\n -3.25269561e-04  1.56054288e-04  6.48613553e-04 -3.38751706e-05\n  2.60645058e-04  9.47780136e-05 -1.75412701e-04  2.55083141e-04\n  6.23841537e-04 -4.99050540e-04 -6.85711333e-04 -3.88055021e-04\n  3.66595923e-04 -6.86366053e-04 -4.35300899e-04  8.39203931e-05\n  1.94216162e-04 -6.63893938e-04  3.88766552e-04  6.22369917e-05\n  2.96735670e-04  2.22572184e-04  9.68270906e-05  2.58616783e-04\n -2.19294496e-04 -3.72793555e-04 -4.81359893e-05  6.74799900e-04\n  4.15205286e-04 -5.66767761e-04 -2.78978929e-04  4.53207613e-04\n -5.69924479e-04 -5.44379945e-05  4.69844264e-04  9.13787517e-05\n  1.69978943e-04 -2.32992257e-04 -1.94730455e-04 -1.72431770e-04\n -2.17015928e-04 -2.92252749e-04 -5.64640854e-04  4.65388963e-04\n -6.31041417e-04  4.18898824e-04 -1.41281635e-04 -3.62109771e-04\n -1.78116854e-04  6.45580760e-04 -2.33099025e-04  5.38413529e-04\n  5.04136588e-05 -2.42193943e-04 -2.76181556e-04 -8.13010192e-05\n  3.83231818e-04  1.55620844e-04 -4.57490205e-06 -2.68453092e-04\n  5.46865747e-04 -4.18363255e-04 -6.09103372e-05 -3.98884673e-04\n -4.34732734e-04 -4.03999147e-04  1.67039398e-04  2.16919318e-04\n -3.01847904e-04  4.47657163e-04 -8.40048888e-05 -6.50685863e-04\n  6.85773557e-04 -3.63918545e-04  5.28521079e-04  2.01198010e-04\n  6.46212779e-04 -5.38458058e-04 -5.27568511e-04 -6.45443361e-05\n  3.93330731e-04 -4.99800721e-04  2.51006946e-04 -2.54672515e-04\n  5.03621763e-04  1.24293947e-04  7.07394938e-05  4.29084583e-04\n  3.68122215e-04 -6.19801052e-04 -6.28575508e-04  1.00494988e-04\n  4.39645839e-04  2.23180672e-04 -2.58757034e-04  5.59013220e-04\n  4.21478850e-04 -6.84427156e-04  3.47468391e-04 -2.48637021e-04\n  5.76840655e-04  2.53481936e-04 -1.12665057e-05  2.45442439e-04]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Pretrained\ntest_data_dir = os.path.join(gensim.__path__[0], 'test', 'test_data')\nlee_train_file = os.path.join(test_data_dir, 'lee_background.cor')\nlee_test_file = os.path.join(test_data_dir, 'lee.cor')\nimport smart_open\n\ndef read_corpus(fname, tokens_only=False):\n    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n        for i, line in enumerate(f):\n            tokens = gensim.utils.simple_preprocess(line)\n            if tokens_only:\n                yield tokens\n            else:\n                # For training data, add tags\n                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n\ntrain_corpus = list(read_corpus(lee_train_file))\ntest_corpus = list(read_corpus(lee_test_file, tokens_only=True))\nmodel_pre = gensim.models.doc2vec.Doc2Vec(vector_size=vec_size, min_count=2, epochs=40,dm=1)\nmodel_pre.build_vocab(train_corpus)\nmodel_pre.train(train_corpus, total_examples=model_pre.corpus_count, epochs=model_pre.epochs)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:42:03.765806Z","iopub.execute_input":"2023-01-21T08:42:03.766284Z","iopub.status.idle":"2023-01-21T08:42:10.242248Z","shell.execute_reply.started":"2023-01-21T08:42:03.766227Z","shell.execute_reply":"2023-01-21T08:42:10.241113Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dict_vals={}\ndf=pd.read_csv('/kaggle/input/devrev/train_data.csv')\nfor i in range(df.shape[0]):\n    dict_vals[df.iloc[i]['Theme']]=[]\n    \nfor i in range(df.shape[0]):\n    dict_vals[df.iloc[i]['Theme']].append(df.iloc[i]['Paragraph'])\ndict_models={}\nfor i in dict_vals.keys():\n    data=dict_vals[i]\n    tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n    model_semi = gensim.models.doc2vec.Doc2Vec(vector_size=vec_size, min_count=2, epochs=70,dm=1,alpha = 0.025)\n  \n    model_semi.build_vocab(tagged_data)\n\n    for epoch in range(max_epochs):\n        print('iteration {0}'.format(epoch),\"Theme = \",i)\n        model_semi.train(tagged_data,\n                    total_examples=model_semi.corpus_count,\n                    epochs=model_semi.epochs)\n        # decrease the learning rate\n        model_semi.alpha -= 0.0002\n        # fix the learning rate, no decay\n        model_semi.min_alpha = model_semi.alpha\n\n    model_semi.save(i+\"-d2v.model\")\n    dict_models[i]=model_semi\n    print(\"Model Saved\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:42:10.244529Z","iopub.execute_input":"2023-01-21T08:42:10.244824Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"iteration 0 Theme =  Beyoncé\nModel Saved\niteration 0 Theme =  Frédéric_Chopin\nModel Saved\niteration 0 Theme =  Sino-Tibetan_relations_during_the_Ming_dynasty\nModel Saved\niteration 0 Theme =  The_Legend_of_Zelda:_Twilight_Princess\nModel Saved\niteration 0 Theme =  Spectre_(2015_film)\nModel Saved\niteration 0 Theme =  New_York_City\nModel Saved\niteration 0 Theme =  To_Kill_a_Mockingbird\nModel Saved\niteration 0 Theme =  Solar_energy\nModel Saved\niteration 0 Theme =  Kanye_West\nModel Saved\niteration 0 Theme =  Buddhism\nModel Saved\niteration 0 Theme =  American_Idol\nModel Saved\niteration 0 Theme =  Dog\nModel Saved\niteration 0 Theme =  2008_Summer_Olympics_torch_relay\nModel Saved\niteration 0 Theme =  Genome\nModel Saved\niteration 0 Theme =  Comprehensive_school\nModel Saved\niteration 0 Theme =  Republic_of_the_Congo\nModel Saved\niteration 0 Theme =  Prime_minister\nModel Saved\niteration 0 Theme =  Institute_of_technology\nModel Saved\niteration 0 Theme =  Dutch_Republic\nModel Saved\niteration 0 Theme =  Symbiosis\nModel Saved\niteration 0 Theme =  Iranian_languages\nModel Saved\niteration 0 Theme =  Lighting\nModel Saved\niteration 0 Theme =  Separation_of_powers_under_the_United_States_Constitution\nModel Saved\niteration 0 Theme =  Architecture\nModel Saved\niteration 0 Theme =  Southern_Europe\nModel Saved\niteration 0 Theme =  BBC_Television\nModel Saved\niteration 0 Theme =  Arnold_Schwarzenegger\nModel Saved\niteration 0 Theme =  Plymouth\nModel Saved\niteration 0 Theme =  Christian\nModel Saved\niteration 0 Theme =  Sony_Music_Entertainment\nModel Saved\niteration 0 Theme =  Oklahoma_City\nModel Saved\niteration 0 Theme =  Hunter-gatherer\nModel Saved\niteration 0 Theme =  United_Nations_Population_Fund\nModel Saved\niteration 0 Theme =  Russian_Soviet_Federative_Socialist_Republic\nModel Saved\niteration 0 Theme =  Alexander_Graham_Bell\nModel Saved\niteration 0 Theme =  Internet_service_provider\nModel Saved\niteration 0 Theme =  Comics\nModel Saved\niteration 0 Theme =  Saint_Helena\nModel Saved\niteration 0 Theme =  Aspirated_consonant\nModel Saved\niteration 0 Theme =  Hydrogen\nModel Saved\niteration 0 Theme =  Space_Race\nModel Saved\niteration 0 Theme =  BeiDou_Navigation_Satellite_System\nModel Saved\niteration 0 Theme =  Canon_law\nModel Saved\niteration 0 Theme =  Communications_in_Somalia\nModel Saved\niteration 0 Theme =  Boston\nModel Saved\niteration 0 Theme =  Universal_Studios\nModel Saved\niteration 0 Theme =  Estonian_language\nModel Saved\niteration 0 Theme =  Daylight_saving_time\nModel Saved\niteration 0 Theme =  Royal_Institute_of_British_Architects\nModel Saved\niteration 0 Theme =  National_Archives_and_Records_Administration\nModel Saved\niteration 0 Theme =  Tristan_da_Cunha\nModel Saved\niteration 0 Theme =  University_of_Kansas\nModel Saved\niteration 0 Theme =  Arena_Football_League\nModel Saved\niteration 0 Theme =  Bern\nModel Saved\niteration 0 Theme =  Westminster_Abbey\nModel Saved\niteration 0 Theme =  Political_corruption\nModel Saved\niteration 0 Theme =  Classical_music\nModel Saved\niteration 0 Theme =  Slavs\nModel Saved\niteration 0 Theme =  Treaty\nModel Saved\niteration 0 Theme =  Josip_Broz_Tito\nModel Saved\niteration 0 Theme =  Marshall_Islands\nModel Saved\niteration 0 Theme =  Szlachta\nModel Saved\niteration 0 Theme =  Virgil\nModel Saved\niteration 0 Theme =  Alps\nModel Saved\niteration 0 Theme =  Gene\nModel Saved\niteration 0 Theme =  Guinea-Bissau\nModel Saved\niteration 0 Theme =  List_of_numbered_streets_in_Manhattan\nModel Saved\niteration 0 Theme =  Brain\nModel Saved\niteration 0 Theme =  Near_East\nModel Saved\niteration 0 Theme =  Zhejiang\nModel Saved\niteration 0 Theme =  Ministry_of_Defence_(United_Kingdom)\nModel Saved\niteration 0 Theme =  High-definition_television\nModel Saved\niteration 0 Theme =  Wood\nModel Saved\niteration 0 Theme =  Somalis\nModel Saved\niteration 0 Theme =  Middle_Ages\nModel Saved\niteration 0 Theme =  Phonology\nModel Saved\niteration 0 Theme =  Computer\nModel Saved\niteration 0 Theme =  Black_people\nModel Saved\niteration 0 Theme =  New_Delhi\nModel Saved\niteration 0 Theme =  Bird_migration\nModel Saved\niteration 0 Theme =  Atlantic_City,_New_Jersey\nModel Saved\niteration 0 Theme =  MP3\nModel Saved\niteration 0 Theme =  House_music\nModel Saved\niteration 0 Theme =  Letter_case\nModel Saved\niteration 0 Theme =  Chihuahua_(state)\nModel Saved\niteration 0 Theme =  Pitch_(music)\nModel Saved\niteration 0 Theme =  England_national_football_team\nModel Saved\niteration 0 Theme =  Houston\nModel Saved\niteration 0 Theme =  Copper\nModel Saved\niteration 0 Theme =  Identity_(social_science)\nModel Saved\niteration 0 Theme =  Himachal_Pradesh\nModel Saved\niteration 0 Theme =  Communication\nModel Saved\niteration 0 Theme =  Computer_security\nModel Saved\niteration 0 Theme =  Orthodox_Judaism\nModel Saved\niteration 0 Theme =  Animal\nModel Saved\niteration 0 Theme =  Beer\nModel Saved\niteration 0 Theme =  Race_and_ethnicity_in_the_United_States_Census\nModel Saved\niteration 0 Theme =  Imperial_College_London\nModel Saved\niteration 0 Theme =  Hanover\nModel Saved\niteration 0 Theme =  Emotion\nModel Saved\niteration 0 Theme =  Old_English\nModel Saved\niteration 0 Theme =  Aircraft_carrier\nModel Saved\niteration 0 Theme =  Federal_Aviation_Administration\nModel Saved\niteration 0 Theme =  Lancashire\nModel Saved\niteration 0 Theme =  Mesozoic\nModel Saved\niteration 0 Theme =  Videoconferencing\nModel Saved\niteration 0 Theme =  Gregorian_calendar\nModel Saved\niteration 0 Theme =  Xbox_360\nModel Saved\niteration 0 Theme =  Military_history_of_the_United_States\nModel Saved\niteration 0 Theme =  Infrared\nModel Saved\niteration 0 Theme =  ASCII\nModel Saved\niteration 0 Theme =  Digestion\nModel Saved\niteration 0 Theme =  Gymnastics\nModel Saved\niteration 0 Theme =  FC_Barcelona\nModel Saved\niteration 0 Theme =  Melbourne\nModel Saved\niteration 0 Theme =  John,_King_of_England\nModel Saved\niteration 0 Theme =  Macintosh\nModel Saved\niteration 0 Theme =  Valencia\nModel Saved\niteration 0 Theme =  General_Electric\nModel Saved\niteration 0 Theme =  United_States_Army\nModel Saved\niteration 0 Theme =  Franco-Prussian_War\nModel Saved\niteration 0 Theme =  Adolescence\nModel Saved\niteration 0 Theme =  Antarctica\nModel Saved\niteration 0 Theme =  Eritrea\nModel Saved\niteration 0 Theme =  Uranium\nModel Saved\niteration 0 Theme =  Circadian_rhythm\nModel Saved\niteration 0 Theme =  Sexual_orientation\nModel Saved\niteration 0 Theme =  Dell\nModel Saved\niteration 0 Theme =  Nintendo_Entertainment_System\nModel Saved\niteration 0 Theme =  Seattle\nModel Saved\niteration 0 Theme =  Memory\nModel Saved\niteration 0 Theme =  Multiracial_American\nModel Saved\niteration 0 Theme =  Ashkenazi_Jews\nModel Saved\niteration 0 Theme =  Pharmaceutical_industry\nModel Saved\niteration 0 Theme =  Umayyad_Caliphate\nModel Saved\niteration 0 Theme =  Asphalt\nModel Saved\niteration 0 Theme =  Queen_Victoria\nModel Saved\niteration 0 Theme =  Israel\nModel Saved\niteration 0 Theme =  Hellenistic_period\nModel Saved\niteration 0 Theme =  Bill_%26_Melinda_Gates_Foundation\nModel Saved\niteration 0 Theme =  Dutch_language\nModel Saved\niteration 0 Theme =  Buckingham_Palace\nModel Saved\niteration 0 Theme =  Incandescent_light_bulb\nModel Saved\niteration 0 Theme =  Arsenal_F.C.\nModel Saved\niteration 0 Theme =  Chicago_Cubs\nModel Saved\niteration 0 Theme =  Korean_War\nModel Saved\niteration 0 Theme =  Copyright_infringement\nModel Saved\niteration 0 Theme =  Greece\nModel Saved\niteration 0 Theme =  Royal_Dutch_Shell\nModel Saved\niteration 0 Theme =  Mammal\nModel Saved\niteration 0 Theme =  East_India_Company\nModel Saved\niteration 0 Theme =  Hokkien\nModel Saved\niteration 0 Theme =  Professional_wrestling\nModel Saved\niteration 0 Theme =  Film_speed\nModel Saved\niteration 0 Theme =  Mexico_City\nModel Saved\niteration 0 Theme =  Napoleon\nModel Saved\niteration 0 Theme =  Germans\nModel Saved\niteration 0 Theme =  Southeast_Asia\nModel Saved\niteration 0 Theme =  Brigham_Young_University\nModel Saved\niteration 0 Theme =  Intellectual_property\nModel Saved\niteration 0 Theme =  Florida\nModel Saved\niteration 0 Theme =  Queen_(band)\nModel Saved\niteration 0 Theme =  Presbyterianism\nModel Saved\niteration 0 Theme =  Thuringia\nModel Saved\niteration 0 Theme =  Predation\nModel Saved\niteration 0 Theme =  British_Empire\nModel Saved\niteration 0 Theme =  Botany\nModel Saved\niteration 0 Theme =  Madonna_(entertainer)\nModel Saved\niteration 0 Theme =  Law_of_the_United_States\nModel Saved\niteration 0 Theme =  Myanmar\nModel Saved\niteration 0 Theme =  Jews\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy import spatial\ndef get_thresh():\n    thresh_pre,thresh_full=[0,0,0,0],[0,0,0,0]\n    dict_thresh_semi={}\n    for i in dict_vals.keys():\n        dict_thresh_semi[i]=[0,0,0,0]\n    \n    for i in range(df.shape[0]):\n        rw=df.iloc[i]\n        if i%1000==0:\n            print(\"At i = \",i)\n        context=rw['Paragraph']\n        ques=rw['Question']\n        test_context = word_tokenize(context.lower())\n        test_ques = word_tokenize(ques.lower())\n        \n        v1_full = model_full.infer_vector(test_context)\n        v2_full = model_full.infer_vector(test_ques)\n        \n        v1_pre = model_pre.infer_vector(test_context)\n        v2_pre = model_pre.infer_vector(test_ques)\n        \n        model_sm=dict_models[rw['Theme']]\n        \n        v1_semi = model_sm.infer_vector(test_context)\n        v2_semi = model_sm.infer_vector(test_ques)\n        \n        result_full = 1 - spatial.distance.cosine(v1_full, v2_full)\n        result_pre = 1 - spatial.distance.cosine(v1_pre, v2_pre)\n        result_semi = 1 - spatial.distance.cosine(v1_semi, v2_semi)\n        \n        if rw['Answer_possible']==True:\n            thresh_pre[0]+=result_pre\n            thresh_full[0]+=result_full\n            dict_thresh_semi[rw['Theme']][0]+=result_semi\n            dict_thresh_semi[rw['Theme']][2]+=1\n            thresh_full[2]+=1\n            thresh_pre[2]+=1\n            \n        else :\n            thresh_pre[1]+=result_pre\n            thresh_full[1]+=result_full\n            dict_thresh_semi[rw['Theme']][1]+=result_semi\n            dict_thresh_semi[rw['Theme']][3]+=1\n            thresh_full[3]+=1\n            thresh_pre[3]+=1\n    \n    return thresh_pre,thresh_full,dict_thresh_semi\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r1,r2,r3=get_thresh()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresh_pre=r1[0]/r1[2]\nthresh_full=r2[0]/r2[2]\nthresh_semi={}\nfor i in dict_vals.keys():\n    thresh_semi[i]=r3[i][0]/r3[i][2]\n\nprint(\"Thresh for pretrained model correct context-question similarity = \",thresh_pre)\nprint(\"Thresh for full trained model correct context-question similarity = \",thresh_full)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresh_answer_full=r2[0]/r2[2]\nthresh_unanswer_full=r2[1]/r2[3]\nthresh_answer_pre=r1[0]/r1[2]\nthresh_unanswer_pre=r1[1]/r1[3]\ndict_thresh_semi={}\nfor i in dict_vals.keys():\n        dict_thresh_semi[i]=[0,0]\nfor i in r3.keys():\n    dict_thresh_semi[i][0]=r3[i][0]/r3[i][2]\n    dict_thresh_semi[i][1]=r3[i][1]/r3[i][3]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_context_embed={}\nfor i in range(df.shape[0]):\n    dict_context_embed[i]=[]\nfor i in range(df.shape[0]):\n    rw=df.iloc[i]\n    if (i)%1000==0:\n        print(\"At i = \",i)\n    context=rw['Paragraph']\n    test_context = word_tokenize(context.lower())\n    v1_full = model_full.infer_vector(test_context)\n    v1_pre = model_pre.infer_vector(test_context)\n#     model_sm=dict_models[rw['Theme']]\n#     v1_semi = model_sm.infer_vector(test_context)\n    dict_context_embed[i]=[v1_pre,v1_full]\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_context=[]\nsample_ques=\"None\"\nsample_theme=\"None\"\nsample_ids=[]\nfor i in range(5):\n    rw=df.iloc[i]\n    sample_context.append(rw['Paragraph'])\n    sample_ques=rw['Question']\n    sample_theme=rw['Theme']\n    sample_ids.append(i)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:17:32.978668Z","iopub.execute_input":"2023-01-21T08:17:32.979377Z","iopub.status.idle":"2023-01-21T08:17:32.985724Z","shell.execute_reply.started":"2023-01-21T08:17:32.979341Z","shell.execute_reply":"2023-01-21T08:17:32.984804Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\nencoded_inputs = tokenizer(\n    questions=[\"What is love ?\",\"What is love ?\",\"What is love ?\"],\n    titles=[\"Haddaway\",\"Haddaway\",\"Haddaway\"],\n    texts=[\"'What Is Love' is a song recorded by the artist Haddaway\",\"'What Is Love' is a song recorded by the artist Haddaway\",\"'What Is Love' is a song recorded by the artist Haddaway\"],\n    return_tensors=\"tf\",\n)\noutputs = model(encoded_inputs)\nstart_logits = outputs.start_logits\nend_logits = outputs.end_logits\nrelevance_logits = outputs.relevance_logits","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:19:14.328248Z","iopub.execute_input":"2023-01-21T08:19:14.328990Z","iopub.status.idle":"2023-01-21T08:19:14.444289Z","shell.execute_reply.started":"2023-01-21T08:19:14.328957Z","shell.execute_reply":"2023-01-21T08:19:14.443351Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"start_indices=np.argmax(start_logits.numpy(),axis=1).tolist()\nend_indices=np.argmax(end_logits.numpy(),axis=1).tolist()\nbest_ans=np.argmax(relevance_logits.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:23:29.277185Z","iopub.execute_input":"2023-01-21T08:23:29.277553Z","iopub.status.idle":"2023-01-21T08:23:29.283886Z","shell.execute_reply.started":"2023-01-21T08:23:29.277523Z","shell.execute_reply":"2023-01-21T08:23:29.282787Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(encoded_inputs['input_ids'][best_ans][start_indices[best_ans]:end_indices[best_ans]+1])","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:23:34.734212Z","iopub.execute_input":"2023-01-21T08:23:34.734944Z","iopub.status.idle":"2023-01-21T08:23:34.744005Z","shell.execute_reply.started":"2023-01-21T08:23:34.734901Z","shell.execute_reply":"2023-01-21T08:23:34.742971Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"'a song'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TFDPRReader, DPRReaderTokenizer\n\ntokenizer = DPRReaderTokenizer.from_pretrained(\"facebook/dpr-reader-single-nq-base\")\nmodel = TFDPRReader.from_pretrained(\"facebook/dpr-reader-single-nq-base\", from_pt=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_reader_answer(ques,retriever_contexts,tm,method='dpr'):\n    if method=='dpr':\n        question=[]\n        theme=[]\n        for i in range(len(retriever_contexts)):\n            question.append(ques)\n            theme.append(tm)\n        encoded_inputs = tokenizer(\n            questions=question,\n            titles=theme,\n            texts=retriever_contexts,\n            return_tensors=\"tf\",\n            padding=True,\n            truncation=True\n        )\n        outputs = model(encoded_inputs)\n        start_logits = outputs.start_logits\n        end_logits = outputs.end_logits\n        relevance_logits = outputs.relevance_logits\n\n        start_indices=np.argmax(start_logits.numpy(),axis=1).tolist()\n        end_indices=np.argmax(end_logits.numpy(),axis=1).tolist()\n        best_ans=np.argmax(relevance_logits.numpy())\n\n    #     print(\"answers are \")\n    #     for i in range(len(start_indices)):\n    #         print(\"Score = \",relevance_logits.numpy()[i])\n    #         print(\"Answer = \",tokenizer.decode(encoded_inputs['input_ids'][i][start_indices[i]:end_indices[i]+1]))\n\n        return tokenizer.decode(encoded_inputs['input_ids'][best_ans][start_indices[best_ans]:end_indices[best_ans]+1]),relevance_logits.numpy()[best_ans]\n    \n    elif method=='roberta':\n        return None","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:28:51.939730Z","iopub.execute_input":"2023-01-21T08:28:51.940118Z","iopub.status.idle":"2023-01-21T08:28:51.951973Z","shell.execute_reply.started":"2023-01-21T08:28:51.940089Z","shell.execute_reply":"2023-01-21T08:28:51.950983Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"v1,v2=get_reader_answer(sample_ques,sample_context,sample_theme,'dpr')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:29:00.873935Z","iopub.execute_input":"2023-01-21T08:29:00.874352Z","iopub.status.idle":"2023-01-21T08:29:01.071082Z","shell.execute_reply.started":"2023-01-21T08:29:00.874312Z","shell.execute_reply":"2023-01-21T08:29:01.062897Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"v1","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:29:09.484811Z","iopub.execute_input":"2023-01-21T08:29:09.485183Z","iopub.status.idle":"2023-01-21T08:29:09.494965Z","shell.execute_reply.started":"2023-01-21T08:29:09.485153Z","shell.execute_reply":"2023-01-21T08:29:09.494089Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'in the late 1990s as lead singer of r & b'"},"metadata":{}}]},{"cell_type":"code","source":"from scipy import spatial","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:34:19.506730Z","iopub.execute_input":"2023-01-21T08:34:19.507119Z","iopub.status.idle":"2023-01-21T08:34:19.511872Z","shell.execute_reply.started":"2023-01-21T08:34:19.507089Z","shell.execute_reply":"2023-01-21T08:34:19.510807Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def predict(context,questions,context_ids,model_type='full',theme=None,top_k=5,thresh=0.40):\n    sim_scores=[]\n    context_embed=0\n    question_embed=0\n    if model_type=='full':\n        context_embed = model_full.infer_vector(context)\n    elif model_type=='pre':\n        context_embed = model_pre.infer_vector(context)\n    else :\n        model_sm=dict_models[theme]\n        context_embed = model_sm.infer_vector(context)\n    questions_embed=[]\n    for i in range(len(questions)):\n        result1=0\n        if model_type=='full':\n            question_embed = dict_context_embed[context_ids[i]][1]\n            result1 = 1 - spatial.distance.cosine(context_embed, question_embed)\n        elif model_type=='pre':\n            question_embed = dict_context_embed[context_ids[i]][0]\n            result1 = 1 - spatial.distance.cosine(context_embed, question_embed)\n        else :\n            question_embed = dict_context_embed[context_ids[i]][2]\n            result1 = 1 - spatial.distance.cosine(context_embed, question_embed)    \n        questions_embed.append(question_embed)\n        sim_scores.append(result1)\n        \n    array = np.array(sim_scores)\n    indices = np.argsort(array)\n    \n    print(\"Got similarities score as \",array)\n    \n    retriever_contexts=[]\n    for i in range(min(top_k,len(indices))):\n        if array[indices[i]]>=thresh:\n            retriever_contexts.append(questions[indices[i]])\n            print(\"Using context \",questions[indices[i]])\n            \n    answer=\"\"\n    socre=1\n    if len(retriever_contexts)>0:\n        answer,socre=get_reader_answer(context,retriever_contexts,theme,method='dpr')\n        \n    return answer,socre\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:35:36.289186Z","iopub.execute_input":"2023-01-21T08:35:36.289564Z","iopub.status.idle":"2023-01-21T08:35:36.301620Z","shell.execute_reply.started":"2023-01-21T08:35:36.289531Z","shell.execute_reply":"2023-01-21T08:35:36.300695Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"v1,v2=predict(list(sample_ques),sample_context,sample_ids,'pre',sample_theme,3,0.20)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:36:09.192855Z","iopub.execute_input":"2023-01-21T08:36:09.193222Z","iopub.status.idle":"2023-01-21T08:36:09.203015Z","shell.execute_reply.started":"2023-01-21T08:36:09.193190Z","shell.execute_reply":"2023-01-21T08:36:09.202041Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Got similarities score as  [ 0.00314397 -0.00081992 -0.00377745  0.00249629 -0.00714049]\n","output_type":"stream"}]},{"cell_type":"code","source":"v1","metadata":{"execution":{"iopub.status.busy":"2023-01-21T08:36:09.929938Z","iopub.execute_input":"2023-01-21T08:36:09.930506Z","iopub.status.idle":"2023-01-21T08:36:09.941987Z","shell.execute_reply.started":"2023-01-21T08:36:09.930463Z","shell.execute_reply":"2023-01-21T08:36:09.940657Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]}]}